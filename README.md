## ğŸ“š Table of Contents ğŸ“š
- [ğŸŒ Introduction](#-introduction)
- [ğŸ Problems to Solve](#-problems-to-solve)
- [ğŸ¬ Demo](#-demo)
- [ğŸš€ Anticipated Updates for the Project](#-anticipated-updates-for-the-project)
- [âœ¨ Features](#-features)
- [ğŸ›  Prerequisites](#-prerequisites)
- [ğŸ”§ Installation](#-installation)
- [ğŸ¯ Usage](#-usage)
- [ğŸ”„ Memory Initialization](#-memory-initialization)
- [ğŸ’» Technologies Used](#-technologies-used)
- [ğŸ“Š Database Schema](#-database-schema)
- [ğŸš€ Optimizations](#-optimizations)


## ğŸŒ Introduction
Vera is a context-aware virtual assistant powered by OpenAI's GPT-4 and other advanced technologies. Unlike traditional virtual assistants, Vera stores conversations in a Neo4j database and uses this stored data to provide contextually relevant responses.

## ğŸ Problems to Solve

### Excessive Information Consumption

Currently, the code faces a challenge concerning information consumption. An excessive amount of information is being gathered during execution, which may be affecting the efficiency and performance of the program. The primary task is to review and optimize the use of variables and context handling throughout the code to identify and address context accumulation.

#### Steps for resolution:

1. **Variable Review**: Conduct a thorough review of the variables used in the code to understand their role and how they are contributing to information consumption.
   
2. **Context Handling Analysis**: Analyze how context is being handled throughout the code, and how this may be contributing to excessive information consumption.

3. **Optimization**: Implement necessary optimizations to reduce information consumption and improve code efficiency.

4. **Testing and Validation**: Perform tests to validate that the implemented optimizations have resolved the issue without introducing new problems.

Any contribution to help resolve this issue is very welcome. If you have any suggestions or solutions, feel free to open a [new Issue](https://github.com/rubensolano2/LLM-LONG-MEMORY/issues) or submit a [Pull Request](https://github.com/rubensolano2/LLM-LONG-MEMORY/pulls).



## ğŸ¬ Demo
- ğŸ“¹ For a live demonstration of how Vera works, check out.






---
# ğŸš€ Anticipated Updates for the Project

Greetings, it's a pleasure to share the innovative improvements on the horizon for my project. These updates are meticulously designed to optimize the code and strengthen interaction. They are detailed as follows:

## 1. ğŸ•°ï¸ Incorporation of Temporal Awareness in Conversations
There are plans to integrate a temporal awareness functionality, allowing for more precise contextualization in responses. For instance, when inquiring "What time is it?" at 2 p.m., the answer will be "It's 2 p.m." instead of "I don't know." This improvement is a significant step towards more intuitive and coherent interactions.

## 2. ğŸ“„ Ability to Create Summaries
The ability to introduce sibling nodes in the database will be included to add a summary that can optimize data search.

## 3. ğŸ’¡ Generation of New Ideas from Summaries
With this feature, new ideas can be conceived from the summaries of our conversations. This function acts as a breeding ground for inspiration and the exploration of new possibilities based on previous discussions, introducing relevant ideas as new information in the database. This process will be carried out by GPT-4 in parallel to filter out irrelevant ideas.

## 4. ğŸ—ºï¸ Thematization of Conversations
The functionality of thematizing conversations will be introduced, allowing to maintain a clear focus and follow a coherent thematic line throughout the interactions. This improvement will help keep our discussions aligned and create large areas of knowledge within the database itself. The idea is that nodes belonging to the same theme can merge and link together, being prioritized in the information search.

These refined improvements represent exciting steps towards expanding the project's capabilities. Thank you for contributing to the evolution of this project! ğŸ˜„

---

  
## âœ¨ Features
- ğŸ¤ Voice recognition using sounddevice and OpenAI's Whisper ASR
- ğŸ—£ Text-to-speech capabilities with Elevenlabs API
- âŒ¨ï¸ Keyboard macro triggers for ease of use
- ğŸ§  Context-aware conversation using TF-IDF and Neo4j database
- ğŸ“‹ Conversation summary and categorization

## ğŸ›  Prerequisites
- ğŸ Python 3.x
- ğŸ“¦ Neo4j
- ğŸ”‘ Elevenlabs API key
- ğŸ”‘ OpenAI API key
- ğŸ“š Required Python packages: `openai`, `keyboard`, `sounddevice`, `scipy`, `pygame`, `numpy`, `sklearn`

## ğŸ”§ Installation
1ï¸âƒ£ Clone the repository  
2ï¸âƒ£ Install dependencies  
3ï¸âƒ£ Populate the `claves.py` file with your Neo4j, ElevenLabs and OpenAI API keys  
4ï¸âƒ£ Run the main script  

## ğŸ¯ Usage
To initiate Vera, use the hotkey `Ctrl + Alt`. Speak into the microphone, and Vera will respond contextually based on past conversations and the current query.

## ğŸ”„ Memory Initialization
- ğŸ•’ Use Vera for a period of time to build up memories for context-aware interactions.
- ğŸ—‚ Alternatively, you can connect Vera to an existing database to prepopulate her memory.

## ğŸ’» Technologies Used
- ğŸ¤ OpenAI's Whisper for ASR
- ğŸ—£ Elevenlabs for text-to-speech
- ğŸ“¦ Neo4j for storing conversations
- ğŸ“ˆ TF-IDF for contextual understanding
- ğŸ¶ Pygame for audio playback

## ğŸ“Š Database Schema
Vera's database has a `Conversacion` node with properties like `fecha_inicio`, `sentimiento`, `contenido_vera`, `contenido_usuario`, `rank`, `tematica`, and `resumen`.

## ğŸš€ Optimizations
- ğŸ“¡ Persistent database connection: Currently, the database connection is initialized and closed each time the `obtener_contexto` function is called. This could be optimized by maintaining a single open connection or utilizing a shared connection.
